{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea09b30-e330-4b09-85c1-798564822f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "#may need to install some of these packages. \n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import json\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from transformers import set_seed\n",
    "\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "set_seed(seed_value)\n",
    "\n",
    "g = globals()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a053ddf-0933-4a3a-aaa0-6f5cdce5534b",
   "metadata": {},
   "source": [
    "## Dataframe Generation from separate debate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abeb3e4-b249-4b6e-8b4f-f41eea9a962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call every years debate excel sheet and concatenate them\n",
    "files = r\".\\Data\\Raw Data\\Debates\"\n",
    "listi = []\n",
    "for i in os.listdir(files):\n",
    "    df = 'df_'+str(i)\n",
    "    g[df] = pd.read_excel(files+'\\\\'+str(i))\n",
    "    g[df]['count'] = i.split('_')[1][0]\n",
    "    listi.append(g[df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d42af9c-a8b7-4bdc-8186-281c2ee259b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unecessary rows\n",
    "final_df  = pd.concat(listi)\n",
    "final_df.drop(columns = ['Unnamed: 0','text'],inplace = True)\n",
    "final_df = final_df[final_df.Year.notna()]\n",
    "final_df['Year'] =final_df['Year'].astype(int)\n",
    "final_df['speaker'] =final_df['speaker'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17ee5f4-5275-4f8f-98a3-8d76404a2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of moderators to remove\n",
    "with open('.\\Data\\moderators.json', 'r') as json_file:\n",
    "    moderators = json.load(json_file)\n",
    "\n",
    "## Dictionary of candidates to normalize naming \n",
    "with open('.\\Data\\candidates.json', 'r') as json_file:\n",
    "    candidates = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967ef771-f523-4e6e-93b8-30ce12b184c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check who is a modertor\n",
    "def value_check(value):\n",
    "    for i in moderators:\n",
    "        if i.lower() in value:\n",
    "            return True\n",
    "    return False\n",
    "final_df['new_speaker'] = final_df.speaker.apply(value_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802fb031-ff32-4105-bdb1-7de5bf6eb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[final_df.new_speaker == False]\n",
    "final_df = final_df[final_df.sentence.notna()]\n",
    "final_df['len'] = final_df.sentence.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0544a9e-3f47-470b-8dec-93b9051d4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only those speakers in dictionary who are presidential candidates. Normalize their naming conventions across debates \n",
    "final_df = final_df[final_df.speaker.isin([i for i in candidates.keys()])]\n",
    "final_df['speaker'] = final_df['speaker'].map(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfe950-3322-422e-af61-e478c45ccdb3",
   "metadata": {},
   "source": [
    "## BERT Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6389aaf-4e52-4e81-a188-d58f937d63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processor(x):\n",
    "    regex = r'\\[.*?\\]'\n",
    "    regex_punctuation = r'[^\\w\\s]'\n",
    "\n",
    "    x = re.sub(regex, '', x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = re.sub(regex_punctuation, '', x)\n",
    "    x = x.lower()\n",
    "    words = word_tokenize(x)\n",
    "    if len(words)>=5:\n",
    "        filtered_words = [word for word in words if word.lower() and word.isalnum()]\n",
    "    else:\n",
    "        filtered_words = 'delete'\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb2dbf5-1dc4-496a-b459-b51b2db47b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['processed_text'] =final_df.sentence.apply(pre_processor)\n",
    "final_df = final_df[final_df.processed_text != 'd e l e t e']\n",
    "final_df = final_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39cb03ba-fdd7-4950-9cd1-d1fab59f601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic.load('bert_model')\n",
    "\n",
    "#Uncomment to retrain model\n",
    "# model = BERTopic(calculate_probabilities=True)\n",
    "\n",
    "#find topics and their probabilities \n",
    "topics, probabilities = model.transform(final_df.processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bd236e-f81b-403d-91cc-a85dc451d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get topic information and metadata \n",
    "topic_info = model.get_topic_info()\n",
    "document_ids = list(range(len(final_df.processed_text)))\n",
    "\n",
    "# Create a DataFrame mapping documents to topics\n",
    "doc_topic_mapping = pd.DataFrame({'Document_ID': document_ids, 'Topic': topics})\n",
    "\n",
    "# Aggregate this mapping with topic information\n",
    "# This joins the two DataFrames on the topic number\n",
    "merged_info = doc_topic_mapping.merge(topic_info, left_on='Topic', right_on='Topic')\n",
    "\n",
    "#Uncomment below to create a new topic info df and the recode it manually. Recommended to load the recoded topic_info_df in next cell\n",
    "\n",
    "#this is the df that shows us topic number, topic and assigned bagged of words representation \n",
    "# topic_info_df = pd.DataFrame(model.get_topic_info())\n",
    "\n",
    "#We then manually look through this saved df and recode topics and decide which ones to drop \n",
    "# topic_info_df.to_excel(\".\\Data\\topic_info_new_run.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a47d89bd-60d7-4986-8f1f-f2c9328f2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_know_think_president</td>\n",
       "      <td>Drop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0_health_care_insurance_medicare</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1_immigration_border_amnesty_illegally</td>\n",
       "      <td>Immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2_education_schools_teachers_school</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3_energy_climate_clean_fuel</td>\n",
       "      <td>Energy/Climate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                                    Name          Rename\n",
       "0     -1          -1_people_know_think_president            Drop\n",
       "1      0        0_health_care_insurance_medicare      Healthcare\n",
       "2      1  1_immigration_border_amnesty_illegally     Immigration\n",
       "3      2     2_education_schools_teachers_school       Education\n",
       "4      3             3_energy_climate_clean_fuel  Energy/Climate"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call back the edited topic_info_df with he recoding\n",
    "topic_info_df_recoded = pd.read_excel('./Data/topic_info.xlsx')\n",
    "topic_info_df_recoded = topic_info_df_recoded[['Topic','Name','Rename']]\n",
    "topic_info_df_recoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cde00f8-e874-484d-a348-57608528921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we create a dictionary of topic numbers and their probabiltiies \n",
    "topic_mapping = topic_info.set_index('Topic')['Name'].to_dict()\n",
    "\n",
    "#and then reshape the dictionary for easier use \n",
    "dict_i = {}\n",
    "for i in range(probabilities.shape[0]):\n",
    "    prob_dict={}\n",
    "    for j in range(-1, len(probabilities[i])):\n",
    "        prob_dict[topic_mapping[j]] = probabilities[i][j]\n",
    "\n",
    "    #This dictionary for each document, has the raw topic names as keys and associate probabilities as values\n",
    "    dict_i[i] = prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7446471d-ff68-4550-979e-6b9b0c769df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we find the topic with the highest probability and recode it based on our edited topic info excel file we created earlier\n",
    "changes = {}\n",
    "for i in list(dict_i.keys()):\n",
    "    top_three = sorted(dict_i[i].items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    if (topic_info_df_recoded[topic_info_df_recoded.Name == top_three[0][0]]['Rename'].to_numpy()[0].strip() != 'Drop'):\n",
    "        tuple_insert = [topic_info_df_recoded[topic_info_df_recoded.Name == top_three[0][0]]['Rename'].values[0], top_three[0][1]]\n",
    "        changes[i] = tuple_insert\n",
    "    else: \n",
    "        tuple_insert = ['drop','drop']\n",
    "        changes[i]=tuple_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c471f472-f174-4f3d-8252-b35bc4d38e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the topics to the dataframe and drop documents whose topics are not policy related. Recoded as 'Drop' \n",
    "for i in changes.keys():\n",
    "    final_df.loc[i, 'Topic'] = changes[i][0]\n",
    "final_df = final_df[final_df.Topic != 'drop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a86b921e-8de4-421f-977e-687ccb6c47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format meta data and append metadata to be used as doc2vec feature\n",
    "final_df['Topic'] = final_df.Topic.str.replace(' ','_', regex =True)\n",
    "final_df['speaker'] = final_df.speaker.str.replace(' ','_', regex =True)\n",
    "final_df['doc2vec_text'] = final_df.sentence + ' ' + final_df.speaker + '_'+ final_df.Year.astype(str) + ' ' + final_df.Topic\n",
    "final_df['Year'] = final_df.Year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffae8cc1-8787-4c1a-92af-48a8f8750832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Debate</th>\n",
       "      <th>Year</th>\n",
       "      <th>count</th>\n",
       "      <th>new_speaker</th>\n",
       "      <th>len</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>doc2vec_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bill_Bradley</td>\n",
       "      <td>Well, first, let me thank the \"Los Angeles Ti...</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>882</td>\n",
       "      <td>well first let me thank the los angeles times ...</td>\n",
       "      <td>Religion/Faith</td>\n",
       "      <td>Well, first, let me thank the \"Los Angeles Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al_Gore</td>\n",
       "      <td>I want to make one other point. James Madison...</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>536</td>\n",
       "      <td>i want to make one other point james madison i...</td>\n",
       "      <td>Education</td>\n",
       "      <td>I want to make one other point. James Madison...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                                           sentence  \\\n",
       "0  Bill_Bradley   Well, first, let me thank the \"Los Angeles Ti...   \n",
       "3       Al_Gore   I want to make one other point. James Madison...   \n",
       "\n",
       "       Debate  Year count  new_speaker  len  \\\n",
       "0  Democratic  2000     1        False  882   \n",
       "3  Democratic  2000     1        False  536   \n",
       "\n",
       "                                      processed_text           Topic  \\\n",
       "0  well first let me thank the los angeles times ...  Religion/Faith   \n",
       "3  i want to make one other point james madison i...       Education   \n",
       "\n",
       "                                        doc2vec_text  \n",
       "0   Well, first, let me thank the \"Los Angeles Ti...  \n",
       "3   I want to make one other point. James Madison...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "876b2690-2d7a-4ff7-991d-e3b4613a1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe with the fitted topics since random state cannot be set. \n",
    "#We have already saved this file. Uncomment to save your new run and new results\n",
    "\n",
    "#final_df.to_csv('Topic_modelling_final_new_run.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
